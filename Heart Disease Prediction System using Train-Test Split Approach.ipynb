{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">In the Name of Allah, the Most Beneficent, the Most Merciful</h3> </center>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        *----------------------------- AUTHOR_DETAILS -------------------------------*\n",
    "        |                                                                            |\n",
    "        |        Project Title  = Heart Disease Prediction System                    |\n",
    "        |                                                                            |\n",
    "        |        Author         = Ms. Shafeen Noor                                   |\n",
    "        |                                                                            |\n",
    "        |                                                                            |\n",
    "        *----------------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h2 style=\"color:green\">-------------------- PROJECT PURPOSE --------------------</h2> </center>\n",
    "<br>\n",
    "<center><h3>\n",
    "The main purpose of this Project is to demonstrate how the Heart Disease Problem can be treated as a Supervised Machine Learning Problem using Python and Scikit-learn Machine Learning Toolkit </h3>\n",
    "<br>\n",
    "<center><h3> For this Purpose, In Sha Allah, we will execute the Machine Learning Cycle </h3>\n",
    "<br>\n",
    "<center> <h2 style=\"color:green\">-------------------------------------------------------------------------</h2> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Titanic Passenger Survival Prediction System â€“ Machine Learning Cycle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Cycle\n",
    "\n",
    "### Four phases of a Machine Learning Cycle are\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "    Build the Model using Training Data\n",
    "\n",
    "### Testing Phase\n",
    "\n",
    "     Evaluate the performance of Model using Testing Data\n",
    "\n",
    "### Application Phase\n",
    "\n",
    "     Deploy the Model in the Real-world, to predict Real-time unseen Data\n",
    "\n",
    "### Feedback Phase\n",
    "\n",
    "    Take Feedback from the Users and Domain Experts to improve the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Executing Machine Learning Cycle Using a Single File</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Sha Allah, we will follow the following steps to execute the Machine Learning Cycle Using a Single File\n",
    "\n",
    "#### Step 1: Import Libraries\n",
    "\n",
    "#### Step 2: Load Sample Data\n",
    "\n",
    "#### Step 3: Understand and Pre-process Sample Data\n",
    "    \n",
    "    Step 3.1: Understand Sample Data\n",
    "    \n",
    "    Step 3.2: Pre-process Sample Data\n",
    "\n",
    "#### Step 4: Feature Extraction \n",
    "\n",
    "#### Step 5: Label Encoding (Input and Output is converted in Numeric Representation)\n",
    "\n",
    "    Step 5.1: Train the Label Encoder\n",
    "\n",
    "    Step 5.2: Label Encode the Output\n",
    "\n",
    "    Step 5.3: Label Encode the Input \n",
    "\n",
    "#### Step 6: Execute the Training Phase\n",
    "\n",
    "    Step 6.1: Splitting Sample Data into Training Data and Testing Data \n",
    "\n",
    "    Step 6.2: Splitting Input Vectors and Outputs / Labels of Training Data\n",
    "\n",
    "    Step 6.3: Train the Support Vector Classifier\n",
    "\n",
    "    Step 6.4: Save the Trained Model\n",
    "\n",
    "#### Step 7: Execute the Testing Phase \n",
    "\n",
    "    Step 7.1: Splitting Input Vectors and Outputs/Labels of Testing Data\n",
    "    \n",
    "    Step 7.2: Load the Saved Model\n",
    "    \n",
    "    Step 7.3: Evaluate the Performance of Trained Model\n",
    "\n",
    "        Step 7.3.1: Make Predictions with the Trained Model on Testing Data\n",
    "\n",
    "    Step 7.4: Calculate the Accuracy Score\n",
    "\n",
    "#### Step 8: Execute the Application Phase \n",
    "\n",
    "    Step 8.1: Take Input from User \n",
    "\n",
    "    Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)\n",
    "\n",
    "    Step 8.3: Label Encoding of Feature Vector (Exactly Same as Label Encoded Feature Vectors of Sample Data)\n",
    "\n",
    "    Step 8.4: Load the Saved Model\n",
    "\n",
    "    Step 8.5: Model Prediction\n",
    "\n",
    "         Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User\n",
    "\n",
    "#### Step 9: Execute the Feedback Phase \n",
    "\n",
    "#### Step 10: Improve the Model based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in d:\\anaconda\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\lib\\site-packages (from prettytable) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from prettytable import PrettyTable   \n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample Data:\n",
      "============\n",
      "\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    63    1   3       145   233    1        0      150      0      2.3   \n",
      "1    37    1   2       130   250    0        1      187      0      3.5   \n",
      "2    41    0   1       130   204    0        0      172      0      1.4   \n",
      "3    56    1   1       120   236    0        1      178      0      0.8   \n",
      "4    57    0   0       120   354    0        1      163      1      0.6   \n",
      "5    57    1   0       140   192    0        1      148      0      0.4   \n",
      "6    56    0   1       140   294    0        0      153      0      1.3   \n",
      "7    44    1   1       120   263    0        1      173      0      0.0   \n",
      "8    52    1   2       172   199    1        1      162      0      0.5   \n",
      "9    57    1   2       150   168    0        1      174      0      1.6   \n",
      "10   54    1   0       140   239    0        1      160      0      1.2   \n",
      "11   48    0   2       130   275    0        1      139      0      0.2   \n",
      "12   49    1   1       130   266    0        1      171      0      0.6   \n",
      "13   64    1   3       110   211    0        0      144      1      1.8   \n",
      "14   58    0   3       150   283    1        0      162      0      1.0   \n",
      "15   50    0   2       120   219    0        1      158      0      1.6   \n",
      "16   58    0   2       120   340    0        1      172      0      0.0   \n",
      "17   66    0   3       150   226    0        1      114      0      2.6   \n",
      "18   43    1   0       150   247    0        1      171      0      1.5   \n",
      "19   69    0   3       140   239    0        1      151      0      1.8   \n",
      "20   59    1   0       135   234    0        1      161      0      0.5   \n",
      "21   44    1   2       130   233    0        1      179      1      0.4   \n",
      "22   42    1   0       140   226    0        1      178      0      0.0   \n",
      "23   61    1   2       150   243    1        1      137      1      1.0   \n",
      "24   40    1   3       140   199    0        1      178      1      1.4   \n",
      "25   71    0   1       160   302    0        1      162      0      0.4   \n",
      "26   59    1   2       150   212    1        1      157      0      1.6   \n",
      "27   51    1   2       110   175    0        1      123      0      0.6   \n",
      "28   65    0   2       140   417    1        0      157      0      0.8   \n",
      "29   53    1   2       130   197    1        0      152      0      1.2   \n",
      "30   41    0   1       105   198    0        1      168      0      0.0   \n",
      "31   65    1   0       120   177    0        1      140      0      0.4   \n",
      "32   44    1   1       130   219    0        0      188      0      0.0   \n",
      "33   54    1   2       125   273    0        0      152      0      0.5   \n",
      "34   51    1   3       125   213    0        0      125      1      1.4   \n",
      "35   46    0   2       142   177    0        0      160      1      1.4   \n",
      "36   54    0   2       135   304    1        1      170      0      0.0   \n",
      "37   54    1   2       150   232    0        0      165      0      1.6   \n",
      "38   65    0   2       155   269    0        1      148      0      0.8   \n",
      "39   65    0   2       160   360    0        0      151      0      0.8   \n",
      "40   51    0   2       140   308    0        0      142      0      1.5   \n",
      "41   48    1   1       130   245    0        0      180      0      0.2   \n",
      "42   45    1   0       104   208    0        0      148      1      3.0   \n",
      "43   53    0   0       130   264    0        0      143      0      0.4   \n",
      "44   39    1   2       140   321    0        0      182      0      0.0   \n",
      "45   52    1   1       120   325    0        1      172      0      0.2   \n",
      "46   44    1   2       140   235    0        0      180      0      0.0   \n",
      "47   47    1   2       138   257    0        0      156      0      0.0   \n",
      "48   53    0   2       128   216    0        0      115      0      0.0   \n",
      "49   53    0   0       138   234    0        0      160      0      0.0   \n",
      "50   67    1   0       160   286    0        0      108      1      1.5   \n",
      "51   67    1   0       120   229    0        0      129      1      2.6   \n",
      "52   62    0   0       140   268    0        0      160      0      3.6   \n",
      "53   63    1   0       130   254    0        0      147      0      1.4   \n",
      "54   53    1   0       140   203    1        0      155      1      3.1   \n",
      "55   56    1   2       130   256    1        0      142      1      0.6   \n",
      "56   48    1   1       110   229    0        1      168      0      1.0   \n",
      "57   58    1   1       120   284    0        0      160      0      1.8   \n",
      "58   58    1   2       132   224    0        0      173      0      3.2   \n",
      "59   60    1   0       130   206    0        0      132      1      2.4   \n",
      "60   40    1   0       110   167    0        0      114      1      2.0   \n",
      "61   60    1   0       117   230    1        1      160      1      1.4   \n",
      "62   64    1   2       140   335    0        1      158      0      0.0   \n",
      "63   43    1   0       120   177    0        0      120      1      2.5   \n",
      "64   57    1   0       150   276    0        0      112      1      0.6   \n",
      "65   55    1   0       132   353    0        1      132      1      1.2   \n",
      "66   65    0   0       150   225    0        0      114      0      1.0   \n",
      "67   61    0   0       130   330    0        0      169      0      0.0   \n",
      "68   58    1   2       112   230    0        0      165      0      2.5   \n",
      "69   50    1   0       150   243    0        0      128      0      2.6   \n",
      "70   44    1   0       112   290    0        0      153      0      0.0   \n",
      "71   60    1   0       130   253    0        1      144      1      1.4   \n",
      "72   54    1   0       124   266    0        0      109      1      2.2   \n",
      "73   50    1   2       140   233    0        1      163      0      0.6   \n",
      "74   41    1   0       110   172    0        0      158      0      0.0   \n",
      "75   51    0   0       130   305    0        1      142      1      1.2   \n",
      "76   58    1   0       128   216    0        0      131      1      2.2   \n",
      "77   54    1   0       120   188    0        1      113      0      1.4   \n",
      "78   60    1   0       145   282    0        0      142      1      2.8   \n",
      "79   60    1   2       140   185    0        0      155      0      3.0   \n",
      "80   59    1   0       170   326    0        0      140      1      3.4   \n",
      "81   46    1   2       150   231    0        1      147      0      3.6   \n",
      "82   67    1   0       125   254    1        1      163      0      0.2   \n",
      "83   62    1   0       120   267    0        1       99      1      1.8   \n",
      "84   65    1   0       110   248    0        0      158      0      0.6   \n",
      "85   44    1   0       110   197    0        0      177      0      0.0   \n",
      "86   60    1   0       125   258    0        0      141      1      2.8   \n",
      "87   58    1   0       150   270    0        0      111      1      0.8   \n",
      "88   68    1   2       180   274    1        0      150      1      1.6   \n",
      "89   62    0   0       160   164    0        0      145      0      6.2   \n",
      "90   52    1   0       128   255    0        1      161      1      0.0   \n",
      "91   59    1   0       110   239    0        0      142      1      1.2   \n",
      "92   60    0   0       150   258    0        0      157      0      2.6   \n",
      "93   49    1   2       120   188    0        1      139      0      2.0   \n",
      "94   59    1   0       140   177    0        1      162      1      0.0   \n",
      "95   57    1   2       128   229    0        0      150      0      0.4   \n",
      "96   61    1   0       120   260    0        1      140      1      3.6   \n",
      "97   39    1   0       118   219    0        1      140      0      1.2   \n",
      "98   61    0   0       145   307    0        0      146      1      1.0   \n",
      "99   56    1   0       125   249    1        0      144      1      1.2   \n",
      "\n",
      "    slope  ca  thal  target  \n",
      "0       0   0     1       1  \n",
      "1       0   0     2       1  \n",
      "2       2   0     2       1  \n",
      "3       2   0     2       1  \n",
      "4       2   0     2       1  \n",
      "5       1   0     1       1  \n",
      "6       1   0     2       1  \n",
      "7       2   0     3       1  \n",
      "8       2   0     3       1  \n",
      "9       2   0     2       1  \n",
      "10      2   0     2       1  \n",
      "11      2   0     2       1  \n",
      "12      2   0     2       1  \n",
      "13      1   0     2       1  \n",
      "14      2   0     2       1  \n",
      "15      1   0     2       1  \n",
      "16      2   0     2       1  \n",
      "17      0   0     2       1  \n",
      "18      2   0     2       1  \n",
      "19      2   2     2       1  \n",
      "20      1   0     3       1  \n",
      "21      2   0     2       1  \n",
      "22      2   0     2       1  \n",
      "23      1   0     2       1  \n",
      "24      2   0     3       1  \n",
      "25      2   2     2       1  \n",
      "26      2   0     2       1  \n",
      "27      2   0     2       1  \n",
      "28      2   1     2       1  \n",
      "29      0   0     2       1  \n",
      "30      2   1     2       1  \n",
      "31      2   0     3       1  \n",
      "32      2   0     2       1  \n",
      "33      0   1     2       1  \n",
      "34      2   1     2       1  \n",
      "35      0   0     2       1  \n",
      "36      2   0     2       1  \n",
      "37      2   0     3       1  \n",
      "38      2   0     2       1  \n",
      "39      2   0     2       1  \n",
      "40      2   1     2       1  \n",
      "41      1   0     2       1  \n",
      "42      1   0     2       1  \n",
      "43      1   0     2       1  \n",
      "44      2   0     2       1  \n",
      "45      2   0     2       1  \n",
      "46      2   0     2       1  \n",
      "47      2   0     2       1  \n",
      "48      2   0     0       1  \n",
      "49      2   0     2       1  \n",
      "50      1   3     2       0  \n",
      "51      1   2     3       0  \n",
      "52      0   2     2       0  \n",
      "53      1   1     3       0  \n",
      "54      0   0     3       0  \n",
      "55      1   1     1       0  \n",
      "56      0   0     3       0  \n",
      "57      1   0     2       0  \n",
      "58      2   2     3       0  \n",
      "59      1   2     3       0  \n",
      "60      1   0     3       0  \n",
      "61      2   2     3       0  \n",
      "62      2   0     2       0  \n",
      "63      1   0     3       0  \n",
      "64      1   1     1       0  \n",
      "65      1   1     3       0  \n",
      "66      1   3     3       0  \n",
      "67      2   0     2       0  \n",
      "68      1   1     3       0  \n",
      "69      1   0     3       0  \n",
      "70      2   1     2       0  \n",
      "71      2   1     3       0  \n",
      "72      1   1     3       0  \n",
      "73      1   1     3       0  \n",
      "74      2   0     3       0  \n",
      "75      1   0     3       0  \n",
      "76      1   3     3       0  \n",
      "77      1   1     3       0  \n",
      "78      1   2     3       0  \n",
      "79      1   0     2       0  \n",
      "80      0   0     3       0  \n",
      "81      1   0     2       0  \n",
      "82      1   2     3       0  \n",
      "83      1   2     3       0  \n",
      "84      2   2     1       0  \n",
      "85      2   1     2       0  \n",
      "86      1   1     3       0  \n",
      "87      2   0     3       0  \n",
      "88      1   0     3       0  \n",
      "89      0   3     3       0  \n",
      "90      2   1     3       0  \n",
      "91      1   1     3       0  \n",
      "92      1   2     3       0  \n",
      "93      1   3     3       0  \n",
      "94      2   1     3       0  \n",
      "95      1   1     3       0  \n",
      "96      1   1     3       0  \n",
      "97      1   0     3       0  \n",
      "98      1   0     3       0  \n",
      "99      1   1     2       0  \n"
     ]
    }
   ],
   "source": [
    "# Load Sample Data\n",
    "\n",
    "''' \n",
    "*---------------------- LOAD_SAMPLE_DATA ------------------------*\n",
    "|     Function: read_csv()                                       |\n",
    "|             Purpose: Read a dataset in CSV file format         |\n",
    "|     Arguments:                                                 |\n",
    "|             path: Path to dataset file                         |\n",
    "|             dataset: Dataset file name                         |\n",
    "|     Return:                                                    |\n",
    "|             dataset: Dataset in DataFrame format               |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    " \n",
    "sample_data = pd.read_csv(\"heart-disease-sample-data.csv\")\n",
    "\n",
    "print(\"\\n\\nSample Data:\")\n",
    "print(\"============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Understand and Pre-process Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Understand Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes in Sample Data:\n",
      "==========================\n",
      "\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Number of Instances in Sample Data: 100\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand Sample Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Sample Data:\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(sample_data.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Sample Data:\",sample_data[\"age\"].count())\n",
    "print(\"========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Pre-process Sample Data\n",
    "    o\tSample Data is already Preprocessed\n",
    "    o\tNo Preprocessing needs to be Performed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Feature Extraction\n",
    "    o\tFeatures are already Extracted\n",
    "    o\tNo Feature Extraction needs to be Performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection:\n",
    "We are selection only four features and droping the rest from the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.drop(['age', 'sex', 'trestbps', 'chol', 'fbs', 'restecg', 'oldpeak', 'slope', 'thal'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Label Encoding the Sample Data (Input and Output is converted in Numeric Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    o\tNo Label encoding required\n",
    "    o\tThe data is already in numeric form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Execute the Training Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.1: Splitting Sample Data into Training Data and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Data:\n",
      "==============\n",
      "\n",
      "    cp  thalach  exang  ca  target\n",
      "43   0      143      0   0       1\n",
      "62   2      158      0   0       0\n",
      "3    1      178      0   0       1\n",
      "71   0      144      1   1       0\n",
      "45   1      172      0   0       1\n",
      "48   2      115      0   0       1\n",
      "6    1      153      0   0       1\n",
      "99   0      144      1   1       0\n",
      "82   0      163      0   2       0\n",
      "76   0      131      1   3       0\n",
      "60   0      114      1   0       0\n",
      "80   0      140      1   0       0\n",
      "90   0      161      1   1       0\n",
      "68   2      165      0   1       0\n",
      "51   0      129      1   2       0\n",
      "27   2      123      0   0       1\n",
      "18   0      171      0   0       1\n",
      "56   1      168      0   0       0\n",
      "63   0      120      1   0       0\n",
      "74   0      158      0   0       0\n",
      "1    2      187      0   0       1\n",
      "61   0      160      1   2       0\n",
      "42   0      148      1   0       1\n",
      "41   1      180      0   0       1\n",
      "4    0      163      1   0       1\n",
      "15   2      158      0   0       1\n",
      "17   3      114      0   0       1\n",
      "40   2      142      0   1       1\n",
      "38   2      148      0   0       1\n",
      "5    0      148      0   0       1\n",
      "91   0      142      1   1       0\n",
      "59   0      132      1   2       0\n",
      "0    3      150      0   0       1\n",
      "34   3      125      1   1       1\n",
      "28   2      157      0   1       1\n",
      "50   0      108      1   3       0\n",
      "11   2      139      0   0       1\n",
      "35   2      160      1   0       1\n",
      "23   2      137      1   0       1\n",
      "52   0      160      0   2       0\n",
      "10   0      160      0   0       1\n",
      "31   0      140      0   0       1\n",
      "66   0      114      0   3       0\n",
      "57   1      160      0   0       0\n",
      "79   2      155      0   0       0\n",
      "85   0      177      0   1       0\n",
      "32   1      188      0   0       1\n",
      "84   0      158      0   2       0\n",
      "14   3      162      0   0       1\n",
      "89   0      145      0   3       0\n",
      "19   3      151      0   2       1\n",
      "29   2      152      0   0       1\n",
      "49   0      160      0   0       1\n",
      "97   0      140      0   0       0\n",
      "98   0      146      1   0       0\n",
      "69   0      128      0   0       0\n",
      "20   0      161      0   0       1\n",
      "94   0      162      1   1       0\n",
      "72   0      109      1   1       0\n",
      "77   0      113      0   1       0\n",
      "25   1      162      0   2       1\n",
      "37   2      165      0   0       1\n",
      "81   2      147      0   0       0\n",
      "46   2      180      0   0       1\n",
      "39   2      151      0   0       1\n",
      "65   0      132      1   1       0\n",
      "58   2      173      0   2       0\n",
      "12   1      171      0   0       1\n",
      "88   2      150      1   0       0\n",
      "70   0      153      0   1       0\n",
      "87   0      111      1   0       0\n",
      "36   2      170      0   0       1\n",
      "21   2      179      1   0       1\n",
      "83   0       99      1   2       0\n",
      "9    2      174      0   0       1\n",
      "96   0      140      1   1       0\n",
      "67   0      169      0   0       0\n",
      "64   0      112      1   1       0\n",
      "47   2      156      0   0       1\n",
      "44   2      182      0   0       1\n",
      "\n",
      "\n",
      "Testing Data:\n",
      "==============\n",
      "\n",
      "    cp  thalach  exang  ca  target\n",
      "26   2      157      0   0       1\n",
      "86   0      141      1   1       0\n",
      "2    1      172      0   0       1\n",
      "55   2      142      1   1       0\n",
      "75   0      142      1   0       0\n",
      "93   2      139      0   3       0\n",
      "16   2      172      0   0       1\n",
      "73   2      163      0   1       0\n",
      "54   0      155      1   0       0\n",
      "95   2      150      0   1       0\n",
      "53   0      147      0   1       0\n",
      "92   0      157      0   2       0\n",
      "78   0      142      1   2       0\n",
      "13   3      144      1   0       1\n",
      "7    1      173      0   0       1\n",
      "30   1      168      0   1       1\n",
      "22   0      178      0   0       1\n",
      "24   3      178      1   0       1\n",
      "33   2      152      0   1       1\n",
      "8    2      162      0   0       1\n"
     ]
    }
   ],
   "source": [
    "# Splitting Sample Data into Training Data and Testing Data\n",
    "\n",
    "''' \n",
    "*------------------- SPLIT_SAMPLE_DATA ---------------------*\n",
    "|        Function: train_test_split()                       |\n",
    "|              Purpose: Split arrays or matrices into       |\n",
    "|                       random train and test subsets       |\n",
    "|        Arguments:                                         |\n",
    "|              arrays: sequence of indexables               |\n",
    "|              test_size: float or int                      |\n",
    "|        Return:                                            |\n",
    "|              splitting: list                              |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "training_data_encoded, testing_data_encoded = train_test_split( sample_data , test_size=0.2 , random_state=0 , shuffle =True)\n",
    "\n",
    "# Save the Training and Testing Data into CSV File \n",
    "\n",
    "training_data_encoded.to_csv(r'training-data-encoded.csv', index = False, header = True)\n",
    "testing_data_encoded.to_csv(r'testing-data-encoded.csv', index = False, header = True)\n",
    "\n",
    "# print Training and Testing Data\n",
    "\n",
    "print(\"\\n\\nTraining Data:\")\n",
    "print(\"==============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(training_data_encoded)\n",
    "print(\"\\n\\nTesting Data:\")\n",
    "print(\"==============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(testing_data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.2: Splitting Input Vectors and Outputs / Labels of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Training Data:\n",
      "==================================================\n",
      "\n",
      "    cp  thalach  exang  ca\n",
      "43   0      143      0   0\n",
      "62   2      158      0   0\n",
      "3    1      178      0   0\n",
      "71   0      144      1   1\n",
      "45   1      172      0   0\n",
      "48   2      115      0   0\n",
      "6    1      153      0   0\n",
      "99   0      144      1   1\n",
      "82   0      163      0   2\n",
      "76   0      131      1   3\n",
      "60   0      114      1   0\n",
      "80   0      140      1   0\n",
      "90   0      161      1   1\n",
      "68   2      165      0   1\n",
      "51   0      129      1   2\n",
      "27   2      123      0   0\n",
      "18   0      171      0   0\n",
      "56   1      168      0   0\n",
      "63   0      120      1   0\n",
      "74   0      158      0   0\n",
      "1    2      187      0   0\n",
      "61   0      160      1   2\n",
      "42   0      148      1   0\n",
      "41   1      180      0   0\n",
      "4    0      163      1   0\n",
      "15   2      158      0   0\n",
      "17   3      114      0   0\n",
      "40   2      142      0   1\n",
      "38   2      148      0   0\n",
      "5    0      148      0   0\n",
      "91   0      142      1   1\n",
      "59   0      132      1   2\n",
      "0    3      150      0   0\n",
      "34   3      125      1   1\n",
      "28   2      157      0   1\n",
      "50   0      108      1   3\n",
      "11   2      139      0   0\n",
      "35   2      160      1   0\n",
      "23   2      137      1   0\n",
      "52   0      160      0   2\n",
      "10   0      160      0   0\n",
      "31   0      140      0   0\n",
      "66   0      114      0   3\n",
      "57   1      160      0   0\n",
      "79   2      155      0   0\n",
      "85   0      177      0   1\n",
      "32   1      188      0   0\n",
      "84   0      158      0   2\n",
      "14   3      162      0   0\n",
      "89   0      145      0   3\n",
      "19   3      151      0   2\n",
      "29   2      152      0   0\n",
      "49   0      160      0   0\n",
      "97   0      140      0   0\n",
      "98   0      146      1   0\n",
      "69   0      128      0   0\n",
      "20   0      161      0   0\n",
      "94   0      162      1   1\n",
      "72   0      109      1   1\n",
      "77   0      113      0   1\n",
      "25   1      162      0   2\n",
      "37   2      165      0   0\n",
      "81   2      147      0   0\n",
      "46   2      180      0   0\n",
      "39   2      151      0   0\n",
      "65   0      132      1   1\n",
      "58   2      173      0   2\n",
      "12   1      171      0   0\n",
      "88   2      150      1   0\n",
      "70   0      153      0   1\n",
      "87   0      111      1   0\n",
      "36   2      170      0   0\n",
      "21   2      179      1   0\n",
      "83   0       99      1   2\n",
      "9    2      174      0   0\n",
      "96   0      140      1   1\n",
      "67   0      169      0   0\n",
      "64   0      112      1   1\n",
      "47   2      156      0   0\n",
      "44   2      182      0   0\n",
      "\n",
      "\n",
      "Outputs/Labels of Training Data:\n",
      "================================\n",
      "\n",
      "  Survived\n",
      "43    1\n",
      "62    0\n",
      "3     1\n",
      "71    0\n",
      "45    1\n",
      "48    1\n",
      "6     1\n",
      "99    0\n",
      "82    0\n",
      "76    0\n",
      "60    0\n",
      "80    0\n",
      "90    0\n",
      "68    0\n",
      "51    0\n",
      "27    1\n",
      "18    1\n",
      "56    0\n",
      "63    0\n",
      "74    0\n",
      "1     1\n",
      "61    0\n",
      "42    1\n",
      "41    1\n",
      "4     1\n",
      "15    1\n",
      "17    1\n",
      "40    1\n",
      "38    1\n",
      "5     1\n",
      "91    0\n",
      "59    0\n",
      "0     1\n",
      "34    1\n",
      "28    1\n",
      "50    0\n",
      "11    1\n",
      "35    1\n",
      "23    1\n",
      "52    0\n",
      "10    1\n",
      "31    1\n",
      "66    0\n",
      "57    0\n",
      "79    0\n",
      "85    0\n",
      "32    1\n",
      "84    0\n",
      "14    1\n",
      "89    0\n",
      "19    1\n",
      "29    1\n",
      "49    1\n",
      "97    0\n",
      "98    0\n",
      "69    0\n",
      "20    1\n",
      "94    0\n",
      "72    0\n",
      "77    0\n",
      "25    1\n",
      "37    1\n",
      "81    0\n",
      "46    1\n",
      "39    1\n",
      "65    0\n",
      "58    0\n",
      "12    1\n",
      "88    0\n",
      "70    0\n",
      "87    0\n",
      "36    1\n",
      "21    1\n",
      "83    0\n",
      "9     1\n",
      "96    0\n",
      "67    0\n",
      "64    0\n",
      "47    1\n",
      "44    1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting Input Vectors and Outputs / Labels of Training Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Training Data:\")\n",
    "print(\"==================================================\\n\")\n",
    "input_vector_train = training_data_encoded.iloc[: , :-1]\n",
    "print(input_vector_train)\n",
    "\n",
    "print(\"\\n\\nOutputs/Labels of Training Data:\")\n",
    "print(\"================================\\n\")\n",
    "print(\"  Survived\")\n",
    "output_label_train = training_data_encoded.iloc[: ,-1]\n",
    "print(output_label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3: Train the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Support Vector Classifier on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n",
      "SVC(gamma='auto', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# Train the Support Vector Classifier\n",
    "\n",
    "''' \n",
    "*--------------- TRAIN_SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "|       Function: svm.SVC()                                        |\n",
    "|           Purpose: Train the Algorithm on Training Data          |\n",
    "|       Arguments:                                                 |\n",
    "|           Training Data: Provide Training Data to the Model      |\n",
    "|       Return:                                                    |\n",
    "|           Parameter: Model return the Training Parameters        |\n",
    "*------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nTraining the Support Vector Classifier on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "svc_model = svm.SVC(gamma='auto',random_state=0)\n",
    "svc_model.fit(input_vector_train,np.ravel(output_label_train))\n",
    "print(svc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.4: Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "\n",
    "''' \n",
    "*--------------------- SAVE_THE_TRAINED_MODEL ---------------------*\n",
    "|        Function: dump()                                          |\n",
    "|             Purpose: Save the Trained Model on your Hard Disk    |\n",
    "|        Arguments:                                                |\n",
    "|             Model: Model Objects                                 |\n",
    "|        Return:                                                   |\n",
    "|             File: Trained Model will be Saved on Hard Disk       |\n",
    "*------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Save the Model in a Pkl File\n",
    "\n",
    "pickle.dump(svc_model, open('svc_trained_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Execute the Testing Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.1: Splitting Input Vectors and Outputs/Labels of Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Testing Data:\n",
      "=================================================\n",
      "\n",
      "    cp  thalach  exang  ca\n",
      "26   2      157      0   0\n",
      "86   0      141      1   1\n",
      "2    1      172      0   0\n",
      "55   2      142      1   1\n",
      "75   0      142      1   0\n",
      "93   2      139      0   3\n",
      "16   2      172      0   0\n",
      "73   2      163      0   1\n",
      "54   0      155      1   0\n",
      "95   2      150      0   1\n",
      "53   0      147      0   1\n",
      "92   0      157      0   2\n",
      "78   0      142      1   2\n",
      "13   3      144      1   0\n",
      "7    1      173      0   0\n",
      "30   1      168      0   1\n",
      "22   0      178      0   0\n",
      "24   3      178      1   0\n",
      "33   2      152      0   1\n",
      "8    2      162      0   0\n",
      "\n",
      "\n",
      "Outputs/Labels of Testing Data:\n",
      "==============================\n",
      "\n",
      "  Target\n",
      "26    1\n",
      "86    0\n",
      "2     1\n",
      "55    0\n",
      "75    0\n",
      "93    0\n",
      "16    1\n",
      "73    0\n",
      "54    0\n",
      "95    0\n",
      "53    0\n",
      "92    0\n",
      "78    0\n",
      "13    1\n",
      "7     1\n",
      "30    1\n",
      "22    1\n",
      "24    1\n",
      "33    1\n",
      "8     1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting Input Vectors and Outputs/Labels of Testing Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Testing Data:\")\n",
    "print(\"=================================================\\n\")\n",
    "input_vector_test = testing_data_encoded.iloc[: , :-1]\n",
    "print(input_vector_test)\n",
    "\n",
    "print(\"\\n\\nOutputs/Labels of Testing Data:\")\n",
    "print(\"==============================\\n\")\n",
    "print(\"  Target\")\n",
    "output_label_test = testing_data_encoded.iloc[: ,-1]\n",
    "print(output_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.2: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('svc_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.3: Evaluate the Machine Learning Model\n",
    "### Step 7.3.1: Make Predictions with the Trained Models on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predictions Returned by svc_trained_model:\n",
      "==========================================\n",
      "\n",
      "    cp  thalach  exang  ca  target  Predictions\n",
      "26   2      157      0   0       1            1\n",
      "86   0      141      1   1       0            0\n",
      "2    1      172      0   0       1            1\n",
      "55   2      142      1   1       0            1\n",
      "75   0      142      1   0       0            0\n",
      "93   2      139      0   3       0            1\n",
      "16   2      172      0   0       1            1\n",
      "73   2      163      0   1       0            1\n",
      "54   0      155      1   0       0            0\n",
      "95   2      150      0   1       0            1\n",
      "53   0      147      0   1       0            1\n",
      "92   0      157      0   2       0            0\n",
      "78   0      142      1   2       0            0\n",
      "13   3      144      1   0       1            1\n",
      "7    1      173      0   0       1            1\n",
      "30   1      168      0   1       1            0\n",
      "22   0      178      0   0       1            1\n",
      "24   3      178      1   0       1            1\n",
      "33   2      152      0   1       1            1\n",
      "8    2      162      0   0       1            1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Machine Learning Model\n",
    "\n",
    "''' \n",
    "*--------------------- EVALUATE_MACHINE_LEARNING_MODEL ----------------------*\n",
    "|       Function: Predict()                                                  |\n",
    "|             Purpose: Make a Prediction using Algorithm on Test Data        |\n",
    "|       Arguments:                                                           |\n",
    "|            Testing Data: Provide Test data to the Trained Model            |\n",
    "|       Return:                                                              |\n",
    "|            Predictions: Model return Predictions                           |\n",
    "*----------------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Provide Test data to the Trained Model\n",
    "\n",
    "model_predictions = model.predict(input_vector_test)\n",
    "testing_data_encoded.copy(deep=True)\n",
    "pd.options.mode.chained_assignment = None\n",
    "testing_data_encoded[\"Predictions\"] = model_predictions\n",
    "\n",
    "# Save the Predictions into CSV File\n",
    "\n",
    "testing_data_encoded.to_csv(r'model-predictions.csv', index = False, header = True)\n",
    "\n",
    "model_predictions = testing_data_encoded \n",
    "print(\"\\n\\nPredictions Returned by svc_trained_model:\")\n",
    "print(\"==========================================\\n\")\n",
    "print(model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.4: Calculate the Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy Score:\n",
      "===============\n",
      "\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Accuracy Score\n",
    "\n",
    "''' \n",
    "/*------------------------ CALCULATE_ACCURACY_SCORE -------------------*\n",
    "|          Function: accuracy_score()                                  |\n",
    "|                Purpose: Evaluate the algorithm on Testing data       |\n",
    "|          Arguments:                                                  |\n",
    "|                Prediction: Predicted values                          |\n",
    "|                Label: Actual values                                  |\n",
    "|          Return:                                                     |\n",
    "|                Accuracy: Accuracy Score                              |\n",
    "*----------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Calculate the Accuracy\n",
    "\n",
    "model_accuracy_score = accuracy_score(model_predictions[\"target\"],model_predictions[\"Predictions\"])\n",
    "\n",
    "print(\"\\n\\nAccuracy Score:\")\n",
    "print(\"===============\\n\")\n",
    "print(round(model_accuracy_score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Execute the Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.1: Take Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Input from User\n",
    "\n",
    "''' \n",
    "*---------------- TAKE_USER_INPUT ----------------*\n",
    "'''\n",
    "\n",
    "cp_input = int(input(\"Enter your cp level: \"))\n",
    "thalach_input = int(input(\"Enter your maximum heart rate achieved: \"))\n",
    "exang_input = int(input(\"Enter whether you experienced exercise-induced angina (0 for no, 1 for yes): \"))\n",
    "oldpeak_input = float(input(\"Enter your ST depression induced by exercise relative to rest: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert User Input into Feature Vector\n",
    "\n",
    "user_input = pd.DataFrame({ 'cp': [cp_input],'thalach': [thalach_input],'exang': [exang_input],'oldpeak': [oldpeak_input]})\n",
    "\n",
    "print(\"\\n\\nUser Input Feature Vector:\")\n",
    "print(\"==========================\\n\")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3: Label Encoding of Feature Vector (Exactly Same as Label Encoded Feature Vectors of Sample Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no label encoding required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.4: Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*----------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                          |\n",
    "|             Purpose: Method to Load Previously Saved Model        |\n",
    "|         Arguments:                                                |\n",
    "|               Model: Trained Model                                |\n",
    "|         Return:                                                   |\n",
    "|               File: Saved Model will be Loaded in Memory          |\n",
    "*-------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('svc_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.5: Model Prediction\n",
    "### Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of Unseen Instance\n",
    "\n",
    "''' \n",
    "*----------------------------  MODEL_PREDICTION --------------------------*\n",
    "|           Function: predict()                                           |\n",
    "|                 Purpose: Use Trained Model to Predict the Output        |\n",
    "|                          of Unseen Instances                            |\n",
    "|           Arguments:                                                    |\n",
    "|                 User Data: Label Encoded Feature Vector of              |\n",
    "|                            Unseen Instances                             |\n",
    "|           Return:                                                       |\n",
    "|                 Survival: Survived or Not Survived                      |\n",
    "*-------------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Make a Prediction on Unseen Data\n",
    "\n",
    "predicted_survival = model.predict(user_input)\n",
    "\n",
    "if(predicted_survival == 1): \n",
    "    prediction = \"Has heart disease\"\n",
    "if(predicted_survival == 0):\n",
    "    prediction = \"doess not have heart disease\"\n",
    "\n",
    "# Add the Prediction in a Pretty Table\n",
    "\n",
    "pretty_table = PrettyTable()\n",
    "pretty_table.add_column(\"       ** Prediction **       \",[prediction])\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Execute the Feedback Phase\n",
    "## A Two-Step Process\n",
    "### Step 01: After some time, take Feedback from\n",
    "    o\tDomain Experts and Users on deployed Titanic Passenger Survival Prediction System\n",
    "### Step 02: Make a List of Possible Improvements based on Feedback received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Improve Model based on Feedback\n",
    "### There is Always Room for Improvement\n",
    "### Based on Feedback from Domain Experts and Users\n",
    "    o\tImprove your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">JAZAK ALLAH KHAIR</h3> \n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
